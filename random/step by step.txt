This script scrapes all manga from manhuaus.com, page by page.
It collects title, URL, cover image, and chapters.
Stores everything in manga_list.json.
It’s smart enough to update existing entries instead of overwriting.

1 scraper.py
den finder all manga main page urls

----------------------------------------------------------------------------------------------------------------------------------------

Loads a list of manga URLs.
Fetches each manga’s full details page.
Extracts:
Rank, alternative titles, genres, status, bookmarks, summary.
All chapters with proper release dates.
Sorts chapters numerically.
Saves each manga into a separate JSON file.
Skips already downloaded manga for efficiency.
It’s essentially the second stage of your scraping pipeline, after the first script that just collected manga list and basic info.

2 scraper step 2.py
finder al dataen fra main manga pagen

----------------------------------------------------------------------------------------------------------------------------------------

Updates existing manga JSON files with missing chapters.
Downloads chapter images.
Supports concurrent image fetching for speed.
Maintains logs and a summary of updates.
Normalizes and sorts all chapters.
Completes the pipeline started by your first two scripts:
Scrape manga list → manga_list.json.
Scrape manga details → individual JSON per manga.
Scrape chapter images & update missing data → final enriched manga JSON files.

3 scraper step 3.py
finds all the image urls for each chapter

----------------------------------------------------------------------------------------------------------------------------------------

This script is the final packaging stage of your manga scraping pipeline:
Takes manga JSON files from manga_data (from previous scrapers).
Creates a folder per manga (CamelCase slug).
Creates a chapters/ folder with JSON files for each chapter.
Builds a main manga.json per manga with references to chapter files.
Updates a global catalog.json for all manga.
Ensures a consistent, clean folder structure suitable for apps or offline readers.

4 scraper step 4.py
covert dataen til app.py
